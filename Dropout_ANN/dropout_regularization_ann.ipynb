{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align='center'>Dropout Regularization In Deep Neural Network</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset basically about if the sonar signal would bounce off metal cyllinder or roughly cyllindrical rocks.\n",
    "\n",
    "Dataset: https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dython.nominal import associations\n",
    "pd.set_option('display.max_columns', None) ##just to enable pandas to show all the available columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>0.0476</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>0.0794</td>\n",
       "      <td>0.0804</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>0.1228</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>0.0357</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1705</td>\n",
       "      <td>0.3257</td>\n",
       "      <td>0.4602</td>\n",
       "      <td>0.6225</td>\n",
       "      <td>0.7327</td>\n",
       "      <td>0.7843</td>\n",
       "      <td>0.7988</td>\n",
       "      <td>0.8261</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9814</td>\n",
       "      <td>0.9620</td>\n",
       "      <td>0.9601</td>\n",
       "      <td>0.9118</td>\n",
       "      <td>0.9086</td>\n",
       "      <td>0.7931</td>\n",
       "      <td>0.5877</td>\n",
       "      <td>0.3474</td>\n",
       "      <td>0.4235</td>\n",
       "      <td>0.4633</td>\n",
       "      <td>0.3410</td>\n",
       "      <td>0.2849</td>\n",
       "      <td>0.2847</td>\n",
       "      <td>0.1742</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>0.1192</td>\n",
       "      <td>0.1154</td>\n",
       "      <td>0.0855</td>\n",
       "      <td>0.1811</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>0.0799</td>\n",
       "      <td>0.0378</td>\n",
       "      <td>0.1268</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.0505</td>\n",
       "      <td>0.0949</td>\n",
       "      <td>0.0677</td>\n",
       "      <td>0.0259</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.0137</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.0563</td>\n",
       "      <td>0.1219</td>\n",
       "      <td>0.1206</td>\n",
       "      <td>0.0246</td>\n",
       "      <td>0.1022</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>0.2291</td>\n",
       "      <td>0.1632</td>\n",
       "      <td>0.2544</td>\n",
       "      <td>0.2807</td>\n",
       "      <td>0.3011</td>\n",
       "      <td>0.3361</td>\n",
       "      <td>0.3024</td>\n",
       "      <td>0.2285</td>\n",
       "      <td>0.2910</td>\n",
       "      <td>0.1316</td>\n",
       "      <td>0.1151</td>\n",
       "      <td>0.3404</td>\n",
       "      <td>0.5562</td>\n",
       "      <td>0.6379</td>\n",
       "      <td>0.6553</td>\n",
       "      <td>0.7384</td>\n",
       "      <td>0.6534</td>\n",
       "      <td>0.5423</td>\n",
       "      <td>0.6877</td>\n",
       "      <td>0.7325</td>\n",
       "      <td>0.7726</td>\n",
       "      <td>0.8229</td>\n",
       "      <td>0.8787</td>\n",
       "      <td>0.9108</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>0.6092</td>\n",
       "      <td>0.7505</td>\n",
       "      <td>0.4775</td>\n",
       "      <td>0.1666</td>\n",
       "      <td>0.3749</td>\n",
       "      <td>0.3776</td>\n",
       "      <td>0.2106</td>\n",
       "      <td>0.5886</td>\n",
       "      <td>0.5628</td>\n",
       "      <td>0.2577</td>\n",
       "      <td>0.5245</td>\n",
       "      <td>0.6149</td>\n",
       "      <td>0.5123</td>\n",
       "      <td>0.3385</td>\n",
       "      <td>0.1499</td>\n",
       "      <td>0.0546</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0335</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.0208</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.0587</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>0.1268</td>\n",
       "      <td>0.1498</td>\n",
       "      <td>0.1436</td>\n",
       "      <td>0.0561</td>\n",
       "      <td>0.0832</td>\n",
       "      <td>0.0672</td>\n",
       "      <td>0.1372</td>\n",
       "      <td>0.2352</td>\n",
       "      <td>0.3208</td>\n",
       "      <td>0.4257</td>\n",
       "      <td>0.5201</td>\n",
       "      <td>0.4914</td>\n",
       "      <td>0.5950</td>\n",
       "      <td>0.7221</td>\n",
       "      <td>0.9039</td>\n",
       "      <td>0.9111</td>\n",
       "      <td>0.8723</td>\n",
       "      <td>0.7686</td>\n",
       "      <td>0.7326</td>\n",
       "      <td>0.5222</td>\n",
       "      <td>0.3097</td>\n",
       "      <td>0.3172</td>\n",
       "      <td>0.2270</td>\n",
       "      <td>0.1640</td>\n",
       "      <td>0.1746</td>\n",
       "      <td>0.1835</td>\n",
       "      <td>0.2048</td>\n",
       "      <td>0.1674</td>\n",
       "      <td>0.2767</td>\n",
       "      <td>0.3104</td>\n",
       "      <td>0.3399</td>\n",
       "      <td>0.4441</td>\n",
       "      <td>0.5046</td>\n",
       "      <td>0.2814</td>\n",
       "      <td>0.1681</td>\n",
       "      <td>0.2633</td>\n",
       "      <td>0.3198</td>\n",
       "      <td>0.1933</td>\n",
       "      <td>0.0934</td>\n",
       "      <td>0.0443</td>\n",
       "      <td>0.0780</td>\n",
       "      <td>0.0722</td>\n",
       "      <td>0.0405</td>\n",
       "      <td>0.0553</td>\n",
       "      <td>0.1081</td>\n",
       "      <td>0.1139</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>0.0265</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.0331</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0228</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.0443</td>\n",
       "      <td>0.0446</td>\n",
       "      <td>0.0235</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>0.2252</td>\n",
       "      <td>0.2611</td>\n",
       "      <td>0.2061</td>\n",
       "      <td>0.1668</td>\n",
       "      <td>0.1801</td>\n",
       "      <td>0.3083</td>\n",
       "      <td>0.3794</td>\n",
       "      <td>0.5364</td>\n",
       "      <td>0.6173</td>\n",
       "      <td>0.7842</td>\n",
       "      <td>0.8392</td>\n",
       "      <td>0.9016</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8911</td>\n",
       "      <td>0.8753</td>\n",
       "      <td>0.7886</td>\n",
       "      <td>0.7156</td>\n",
       "      <td>0.7581</td>\n",
       "      <td>0.6372</td>\n",
       "      <td>0.3210</td>\n",
       "      <td>0.2076</td>\n",
       "      <td>0.2279</td>\n",
       "      <td>0.3309</td>\n",
       "      <td>0.2847</td>\n",
       "      <td>0.1949</td>\n",
       "      <td>0.1671</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>0.1362</td>\n",
       "      <td>0.2212</td>\n",
       "      <td>0.1124</td>\n",
       "      <td>0.1677</td>\n",
       "      <td>0.1039</td>\n",
       "      <td>0.2562</td>\n",
       "      <td>0.2624</td>\n",
       "      <td>0.2236</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>0.1103</td>\n",
       "      <td>0.2831</td>\n",
       "      <td>0.2385</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>0.1483</td>\n",
       "      <td>0.0434</td>\n",
       "      <td>0.0627</td>\n",
       "      <td>0.0513</td>\n",
       "      <td>0.0473</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>0.0274</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0398</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>0.0681</td>\n",
       "      <td>0.0706</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>0.0893</td>\n",
       "      <td>0.0381</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.1303</td>\n",
       "      <td>0.0273</td>\n",
       "      <td>0.0644</td>\n",
       "      <td>0.0712</td>\n",
       "      <td>0.1204</td>\n",
       "      <td>0.0717</td>\n",
       "      <td>0.1224</td>\n",
       "      <td>0.2349</td>\n",
       "      <td>0.3684</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.4925</td>\n",
       "      <td>0.8793</td>\n",
       "      <td>0.9606</td>\n",
       "      <td>0.8786</td>\n",
       "      <td>0.6905</td>\n",
       "      <td>0.6937</td>\n",
       "      <td>0.5674</td>\n",
       "      <td>0.6540</td>\n",
       "      <td>0.7802</td>\n",
       "      <td>0.7575</td>\n",
       "      <td>0.5836</td>\n",
       "      <td>0.6316</td>\n",
       "      <td>0.8108</td>\n",
       "      <td>0.9039</td>\n",
       "      <td>0.8647</td>\n",
       "      <td>0.6695</td>\n",
       "      <td>0.4027</td>\n",
       "      <td>0.2370</td>\n",
       "      <td>0.2685</td>\n",
       "      <td>0.3662</td>\n",
       "      <td>0.3267</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.2996</td>\n",
       "      <td>0.2205</td>\n",
       "      <td>0.1163</td>\n",
       "      <td>0.0635</td>\n",
       "      <td>0.0465</td>\n",
       "      <td>0.0422</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "77   0.0336  0.0294  0.0476  0.0539  0.0794  0.0804  0.1136  0.1228  0.1235   \n",
       "142  0.0526  0.0563  0.1219  0.1206  0.0246  0.1022  0.0539  0.0439  0.2291   \n",
       "102  0.0587  0.1210  0.1268  0.1498  0.1436  0.0561  0.0832  0.0672  0.1372   \n",
       "130  0.0443  0.0446  0.0235  0.1008  0.2252  0.2611  0.2061  0.1668  0.1801   \n",
       "36   0.0094  0.0166  0.0398  0.0359  0.0681  0.0706  0.1020  0.0893  0.0381   \n",
       "\n",
       "         9       10      11      12      13      14      15      16      17  \\\n",
       "77   0.0842  0.0357  0.0689  0.1705  0.3257  0.4602  0.6225  0.7327  0.7843   \n",
       "142  0.1632  0.2544  0.2807  0.3011  0.3361  0.3024  0.2285  0.2910  0.1316   \n",
       "102  0.2352  0.3208  0.4257  0.5201  0.4914  0.5950  0.7221  0.9039  0.9111   \n",
       "130  0.3083  0.3794  0.5364  0.6173  0.7842  0.8392  0.9016  1.0000  0.8911   \n",
       "36   0.1328  0.1303  0.0273  0.0644  0.0712  0.1204  0.0717  0.1224  0.2349   \n",
       "\n",
       "         18      19      20      21      22      23      24      25      26  \\\n",
       "77   0.7988  0.8261  1.0000  0.9814  0.9620  0.9601  0.9118  0.9086  0.7931   \n",
       "142  0.1151  0.3404  0.5562  0.6379  0.6553  0.7384  0.6534  0.5423  0.6877   \n",
       "102  0.8723  0.7686  0.7326  0.5222  0.3097  0.3172  0.2270  0.1640  0.1746   \n",
       "130  0.8753  0.7886  0.7156  0.7581  0.6372  0.3210  0.2076  0.2279  0.3309   \n",
       "36   0.3684  0.3918  0.4925  0.8793  0.9606  0.8786  0.6905  0.6937  0.5674   \n",
       "\n",
       "         27      28      29      30      31      32      33      34      35  \\\n",
       "77   0.5877  0.3474  0.4235  0.4633  0.3410  0.2849  0.2847  0.1742  0.0549   \n",
       "142  0.7325  0.7726  0.8229  0.8787  0.9108  0.6705  0.6092  0.7505  0.4775   \n",
       "102  0.1835  0.2048  0.1674  0.2767  0.3104  0.3399  0.4441  0.5046  0.2814   \n",
       "130  0.2847  0.1949  0.1671  0.1025  0.1362  0.2212  0.1124  0.1677  0.1039   \n",
       "36   0.6540  0.7802  0.7575  0.5836  0.6316  0.8108  0.9039  0.8647  0.6695   \n",
       "\n",
       "         36      37      38      39      40      41      42      43      44  \\\n",
       "77   0.1192  0.1154  0.0855  0.1811  0.1264  0.0799  0.0378  0.1268  0.1125   \n",
       "142  0.1666  0.3749  0.3776  0.2106  0.5886  0.5628  0.2577  0.5245  0.6149   \n",
       "102  0.1681  0.2633  0.3198  0.1933  0.0934  0.0443  0.0780  0.0722  0.0405   \n",
       "130  0.2562  0.2624  0.2236  0.1180  0.1103  0.2831  0.2385  0.0255  0.1967   \n",
       "36   0.4027  0.2370  0.2685  0.3662  0.3267  0.2200  0.2996  0.2205  0.1163   \n",
       "\n",
       "         45      46      47      48      49      50      51      52      53  \\\n",
       "77   0.0505  0.0949  0.0677  0.0259  0.0170  0.0033  0.0150  0.0111  0.0032   \n",
       "142  0.5123  0.3385  0.1499  0.0546  0.0270  0.0380  0.0339  0.0149  0.0335   \n",
       "102  0.0553  0.1081  0.1139  0.0767  0.0265  0.0215  0.0331  0.0111  0.0088   \n",
       "130  0.1483  0.0434  0.0627  0.0513  0.0473  0.0248  0.0274  0.0205  0.0141   \n",
       "36   0.0635  0.0465  0.0422  0.0174  0.0172  0.0134  0.0141  0.0191  0.0145   \n",
       "\n",
       "         54      55      56      57      58      59 60  \n",
       "77   0.0035  0.0169  0.0137  0.0015  0.0069  0.0051  R  \n",
       "142  0.0376  0.0174  0.0132  0.0103  0.0364  0.0208  M  \n",
       "102  0.0158  0.0122  0.0038  0.0101  0.0228  0.0124  M  \n",
       "130  0.0185  0.0055  0.0045  0.0115  0.0152  0.0100  M  \n",
       "36   0.0065  0.0129  0.0217  0.0087  0.0077  0.0122  R  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./sonar_dataset.csv\", header=None)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 61)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 208 entries, 0 to 207\n",
      "Data columns (total 61 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       208 non-null    float64\n",
      " 1   1       208 non-null    float64\n",
      " 2   2       208 non-null    float64\n",
      " 3   3       208 non-null    float64\n",
      " 4   4       208 non-null    float64\n",
      " 5   5       208 non-null    float64\n",
      " 6   6       208 non-null    float64\n",
      " 7   7       208 non-null    float64\n",
      " 8   8       208 non-null    float64\n",
      " 9   9       208 non-null    float64\n",
      " 10  10      208 non-null    float64\n",
      " 11  11      208 non-null    float64\n",
      " 12  12      208 non-null    float64\n",
      " 13  13      208 non-null    float64\n",
      " 14  14      208 non-null    float64\n",
      " 15  15      208 non-null    float64\n",
      " 16  16      208 non-null    float64\n",
      " 17  17      208 non-null    float64\n",
      " 18  18      208 non-null    float64\n",
      " 19  19      208 non-null    float64\n",
      " 20  20      208 non-null    float64\n",
      " 21  21      208 non-null    float64\n",
      " 22  22      208 non-null    float64\n",
      " 23  23      208 non-null    float64\n",
      " 24  24      208 non-null    float64\n",
      " 25  25      208 non-null    float64\n",
      " 26  26      208 non-null    float64\n",
      " 27  27      208 non-null    float64\n",
      " 28  28      208 non-null    float64\n",
      " 29  29      208 non-null    float64\n",
      " 30  30      208 non-null    float64\n",
      " 31  31      208 non-null    float64\n",
      " 32  32      208 non-null    float64\n",
      " 33  33      208 non-null    float64\n",
      " 34  34      208 non-null    float64\n",
      " 35  35      208 non-null    float64\n",
      " 36  36      208 non-null    float64\n",
      " 37  37      208 non-null    float64\n",
      " 38  38      208 non-null    float64\n",
      " 39  39      208 non-null    float64\n",
      " 40  40      208 non-null    float64\n",
      " 41  41      208 non-null    float64\n",
      " 42  42      208 non-null    float64\n",
      " 43  43      208 non-null    float64\n",
      " 44  44      208 non-null    float64\n",
      " 45  45      208 non-null    float64\n",
      " 46  46      208 non-null    float64\n",
      " 47  47      208 non-null    float64\n",
      " 48  48      208 non-null    float64\n",
      " 49  49      208 non-null    float64\n",
      " 50  50      208 non-null    float64\n",
      " 51  51      208 non-null    float64\n",
      " 52  52      208 non-null    float64\n",
      " 53  53      208 non-null    float64\n",
      " 54  54      208 non-null    float64\n",
      " 55  55      208 non-null    float64\n",
      " 56  56      208 non-null    float64\n",
      " 57  57      208 non-null    float64\n",
      " 58  58      208 non-null    float64\n",
      " 59  59      208 non-null    float64\n",
      " 60  60      208 non-null    object \n",
      "dtypes: float64(60), object(1)\n",
      "memory usage: 99.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "31    0\n",
       "33    0\n",
       "34    0\n",
       "35    0\n",
       "     ..\n",
       "25    0\n",
       "26    0\n",
       "27    0\n",
       "28    0\n",
       "60    0\n",
       "Length: 61, dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for nan values\n",
    "df.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "            17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "            34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "            51, 52, 53, 54, 55, 56, 57, 58, 59, 60],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    111\n",
       "R     97\n",
       "Name: 60, dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[60].value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "111 samples metal, and 97 rocks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    R\n",
       "1    R\n",
       "2    R\n",
       "3    R\n",
       "4    R\n",
       "Name: 60, dtype: object"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(60, axis=1)\n",
    "y = df[60]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     R\n",
       "168  0\n",
       "187  0\n",
       "157  0\n",
       "91   1\n",
       "200  0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(y, drop_first=True)\n",
    "y.sample(5) # R --> 1 and M --> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R\n",
       "0    111\n",
       "1     97\n",
       "dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>0.1609</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.2238</td>\n",
       "      <td>0.0645</td>\n",
       "      <td>0.0660</td>\n",
       "      <td>0.2273</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>0.2999</td>\n",
       "      <td>0.5078</td>\n",
       "      <td>0.4797</td>\n",
       "      <td>0.5783</td>\n",
       "      <td>0.5071</td>\n",
       "      <td>0.4328</td>\n",
       "      <td>0.5550</td>\n",
       "      <td>0.6711</td>\n",
       "      <td>0.6415</td>\n",
       "      <td>0.7104</td>\n",
       "      <td>0.8080</td>\n",
       "      <td>0.6791</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.2604</td>\n",
       "      <td>0.5121</td>\n",
       "      <td>0.7547</td>\n",
       "      <td>0.8537</td>\n",
       "      <td>0.8507</td>\n",
       "      <td>0.6692</td>\n",
       "      <td>0.6097</td>\n",
       "      <td>0.4943</td>\n",
       "      <td>0.2744</td>\n",
       "      <td>0.0510</td>\n",
       "      <td>0.2834</td>\n",
       "      <td>0.2825</td>\n",
       "      <td>0.4256</td>\n",
       "      <td>0.2641</td>\n",
       "      <td>0.1386</td>\n",
       "      <td>0.1051</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>0.0383</td>\n",
       "      <td>0.0324</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>0.4918</td>\n",
       "      <td>0.6552</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>0.7797</td>\n",
       "      <td>0.7464</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8874</td>\n",
       "      <td>0.8024</td>\n",
       "      <td>0.7818</td>\n",
       "      <td>0.5212</td>\n",
       "      <td>0.4052</td>\n",
       "      <td>0.3957</td>\n",
       "      <td>0.3914</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.3271</td>\n",
       "      <td>0.2767</td>\n",
       "      <td>0.4423</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>0.3788</td>\n",
       "      <td>0.2947</td>\n",
       "      <td>0.1984</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>0.4182</td>\n",
       "      <td>0.3835</td>\n",
       "      <td>0.1057</td>\n",
       "      <td>0.1840</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.1674</td>\n",
       "      <td>0.0583</td>\n",
       "      <td>0.1401</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.0621</td>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.0530</td>\n",
       "      <td>0.0742</td>\n",
       "      <td>0.0409</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>0.7060</td>\n",
       "      <td>0.5544</td>\n",
       "      <td>0.5320</td>\n",
       "      <td>0.6479</td>\n",
       "      <td>0.6931</td>\n",
       "      <td>0.6759</td>\n",
       "      <td>0.7551</td>\n",
       "      <td>0.8929</td>\n",
       "      <td>0.8619</td>\n",
       "      <td>0.7974</td>\n",
       "      <td>0.6737</td>\n",
       "      <td>0.4293</td>\n",
       "      <td>0.3648</td>\n",
       "      <td>0.5331</td>\n",
       "      <td>0.2413</td>\n",
       "      <td>0.5070</td>\n",
       "      <td>0.8533</td>\n",
       "      <td>0.6036</td>\n",
       "      <td>0.8514</td>\n",
       "      <td>0.8512</td>\n",
       "      <td>0.5045</td>\n",
       "      <td>0.1862</td>\n",
       "      <td>0.2709</td>\n",
       "      <td>0.4232</td>\n",
       "      <td>0.3043</td>\n",
       "      <td>0.6116</td>\n",
       "      <td>0.6756</td>\n",
       "      <td>0.5375</td>\n",
       "      <td>0.4719</td>\n",
       "      <td>0.4647</td>\n",
       "      <td>0.2587</td>\n",
       "      <td>0.2129</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>0.1348</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>0.0881</td>\n",
       "      <td>0.1992</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.2261</td>\n",
       "      <td>0.1729</td>\n",
       "      <td>0.2131</td>\n",
       "      <td>0.0693</td>\n",
       "      <td>0.2281</td>\n",
       "      <td>0.4060</td>\n",
       "      <td>0.3973</td>\n",
       "      <td>0.2741</td>\n",
       "      <td>0.3690</td>\n",
       "      <td>0.5556</td>\n",
       "      <td>0.4846</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>0.5334</td>\n",
       "      <td>0.5256</td>\n",
       "      <td>0.2520</td>\n",
       "      <td>0.2090</td>\n",
       "      <td>0.3559</td>\n",
       "      <td>0.6260</td>\n",
       "      <td>0.7340</td>\n",
       "      <td>0.6120</td>\n",
       "      <td>0.3497</td>\n",
       "      <td>0.3953</td>\n",
       "      <td>0.3012</td>\n",
       "      <td>0.5408</td>\n",
       "      <td>0.8814</td>\n",
       "      <td>0.9857</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.6121</td>\n",
       "      <td>0.5006</td>\n",
       "      <td>0.3210</td>\n",
       "      <td>0.3202</td>\n",
       "      <td>0.4295</td>\n",
       "      <td>0.3654</td>\n",
       "      <td>0.2655</td>\n",
       "      <td>0.1576</td>\n",
       "      <td>0.0681</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>0.4152</td>\n",
       "      <td>0.3952</td>\n",
       "      <td>0.4256</td>\n",
       "      <td>0.4135</td>\n",
       "      <td>0.4528</td>\n",
       "      <td>0.5326</td>\n",
       "      <td>0.7306</td>\n",
       "      <td>0.6193</td>\n",
       "      <td>0.2032</td>\n",
       "      <td>0.4636</td>\n",
       "      <td>0.4148</td>\n",
       "      <td>0.4292</td>\n",
       "      <td>0.5730</td>\n",
       "      <td>0.5399</td>\n",
       "      <td>0.3161</td>\n",
       "      <td>0.2285</td>\n",
       "      <td>0.6995</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7262</td>\n",
       "      <td>0.4724</td>\n",
       "      <td>0.5103</td>\n",
       "      <td>0.5459</td>\n",
       "      <td>0.2881</td>\n",
       "      <td>0.0981</td>\n",
       "      <td>0.1951</td>\n",
       "      <td>0.4181</td>\n",
       "      <td>0.4604</td>\n",
       "      <td>0.3217</td>\n",
       "      <td>0.2828</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.1979</td>\n",
       "      <td>0.2444</td>\n",
       "      <td>0.1847</td>\n",
       "      <td>0.0841</td>\n",
       "      <td>0.0692</td>\n",
       "      <td>0.0528</td>\n",
       "      <td>0.0357</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9       10      11      12      13      14      15      16      17  \\\n",
       "0  0.2111  0.1609  0.1582  0.2238  0.0645  0.0660  0.2273  0.3100  0.2999   \n",
       "1  0.2872  0.4918  0.6552  0.6919  0.7797  0.7464  0.9444  1.0000  0.8874   \n",
       "2  0.6194  0.6333  0.7060  0.5544  0.5320  0.6479  0.6931  0.6759  0.7551   \n",
       "3  0.1264  0.0881  0.1992  0.0184  0.2261  0.1729  0.2131  0.0693  0.2281   \n",
       "4  0.4459  0.4152  0.3952  0.4256  0.4135  0.4528  0.5326  0.7306  0.6193   \n",
       "\n",
       "       18      19      20      21      22      23      24      25      26  \\\n",
       "0  0.5078  0.4797  0.5783  0.5071  0.4328  0.5550  0.6711  0.6415  0.7104   \n",
       "1  0.8024  0.7818  0.5212  0.4052  0.3957  0.3914  0.3250  0.3200  0.3271   \n",
       "2  0.8929  0.8619  0.7974  0.6737  0.4293  0.3648  0.5331  0.2413  0.5070   \n",
       "3  0.4060  0.3973  0.2741  0.3690  0.5556  0.4846  0.3140  0.5334  0.5256   \n",
       "4  0.2032  0.4636  0.4148  0.4292  0.5730  0.5399  0.3161  0.2285  0.6995   \n",
       "\n",
       "       27      28      29      30      31      32      33      34      35  \\\n",
       "0  0.8080  0.6791  0.3857  0.1307  0.2604  0.5121  0.7547  0.8537  0.8507   \n",
       "1  0.2767  0.4423  0.2028  0.3788  0.2947  0.1984  0.2341  0.1306  0.4182   \n",
       "2  0.8533  0.6036  0.8514  0.8512  0.5045  0.1862  0.2709  0.4232  0.3043   \n",
       "3  0.2520  0.2090  0.3559  0.6260  0.7340  0.6120  0.3497  0.3953  0.3012   \n",
       "4  1.0000  0.7262  0.4724  0.5103  0.5459  0.2881  0.0981  0.1951  0.4181   \n",
       "\n",
       "       36      37      38      39      40      41      42      43      44  \\\n",
       "0  0.6692  0.6097  0.4943  0.2744  0.0510  0.2834  0.2825  0.4256  0.2641   \n",
       "1  0.3835  0.1057  0.1840  0.1970  0.1674  0.0583  0.1401  0.1628  0.0621   \n",
       "2  0.6116  0.6756  0.5375  0.4719  0.4647  0.2587  0.2129  0.2222  0.2111   \n",
       "3  0.5408  0.8814  0.9857  0.9167  0.6121  0.5006  0.3210  0.3202  0.4295   \n",
       "4  0.4604  0.3217  0.2828  0.2430  0.1979  0.2444  0.1847  0.0841  0.0692   \n",
       "\n",
       "       45      46      47      48      49      50      51      52      53  \\\n",
       "0  0.1386  0.1051  0.1343  0.0383  0.0324  0.0232  0.0027  0.0065  0.0159   \n",
       "1  0.0203  0.0530  0.0742  0.0409  0.0061  0.0125  0.0084  0.0089  0.0048   \n",
       "2  0.0176  0.1348  0.0744  0.0130  0.0106  0.0033  0.0232  0.0166  0.0095   \n",
       "3  0.3654  0.2655  0.1576  0.0681  0.0294  0.0241  0.0121  0.0036  0.0150   \n",
       "4  0.0528  0.0357  0.0085  0.0230  0.0046  0.0156  0.0031  0.0054  0.0105   \n",
       "\n",
       "       54      55      56      57      58      59  \n",
       "0  0.0072  0.0167  0.0180  0.0084  0.0090  0.0032  \n",
       "1  0.0094  0.0191  0.0140  0.0049  0.0052  0.0044  \n",
       "2  0.0180  0.0244  0.0316  0.0164  0.0095  0.0078  \n",
       "3  0.0085  0.0073  0.0050  0.0044  0.0040  0.0117  \n",
       "4  0.0110  0.0015  0.0072  0.0048  0.0107  0.0094  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.0403</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>0.0293</td>\n",
       "      <td>0.0820</td>\n",
       "      <td>0.1342</td>\n",
       "      <td>0.1161</td>\n",
       "      <td>0.0663</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0506</td>\n",
       "      <td>0.0906</td>\n",
       "      <td>0.2545</td>\n",
       "      <td>0.1464</td>\n",
       "      <td>0.1272</td>\n",
       "      <td>0.1223</td>\n",
       "      <td>0.1669</td>\n",
       "      <td>0.1424</td>\n",
       "      <td>0.1285</td>\n",
       "      <td>0.1857</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>0.2547</td>\n",
       "      <td>0.0240</td>\n",
       "      <td>0.1923</td>\n",
       "      <td>0.4753</td>\n",
       "      <td>0.7003</td>\n",
       "      <td>0.6825</td>\n",
       "      <td>0.6443</td>\n",
       "      <td>0.7063</td>\n",
       "      <td>0.5373</td>\n",
       "      <td>0.6601</td>\n",
       "      <td>0.8708</td>\n",
       "      <td>0.9518</td>\n",
       "      <td>0.9605</td>\n",
       "      <td>0.7712</td>\n",
       "      <td>0.6772</td>\n",
       "      <td>0.6431</td>\n",
       "      <td>0.6720</td>\n",
       "      <td>0.6035</td>\n",
       "      <td>0.5155</td>\n",
       "      <td>0.3802</td>\n",
       "      <td>0.2278</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.0801</td>\n",
       "      <td>0.0804</td>\n",
       "      <td>0.0752</td>\n",
       "      <td>0.0566</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.0433</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>0.0449</td>\n",
       "      <td>0.0597</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.0531</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>0.1052</td>\n",
       "      <td>0.2120</td>\n",
       "      <td>0.1640</td>\n",
       "      <td>0.1901</td>\n",
       "      <td>0.3026</td>\n",
       "      <td>0.2019</td>\n",
       "      <td>0.0592</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.3657</td>\n",
       "      <td>0.3809</td>\n",
       "      <td>0.5929</td>\n",
       "      <td>0.6299</td>\n",
       "      <td>0.5801</td>\n",
       "      <td>0.4574</td>\n",
       "      <td>0.4449</td>\n",
       "      <td>0.3691</td>\n",
       "      <td>0.6446</td>\n",
       "      <td>0.8940</td>\n",
       "      <td>0.8978</td>\n",
       "      <td>0.4980</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.1553</td>\n",
       "      <td>0.3666</td>\n",
       "      <td>0.4340</td>\n",
       "      <td>0.3082</td>\n",
       "      <td>0.3024</td>\n",
       "      <td>0.4109</td>\n",
       "      <td>0.5501</td>\n",
       "      <td>0.4129</td>\n",
       "      <td>0.5499</td>\n",
       "      <td>0.5018</td>\n",
       "      <td>0.3132</td>\n",
       "      <td>0.2802</td>\n",
       "      <td>0.2351</td>\n",
       "      <td>0.2298</td>\n",
       "      <td>0.1155</td>\n",
       "      <td>0.0724</td>\n",
       "      <td>0.0621</td>\n",
       "      <td>0.0318</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0196</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.0163</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.0752</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.1487</td>\n",
       "      <td>0.1484</td>\n",
       "      <td>0.2442</td>\n",
       "      <td>0.2822</td>\n",
       "      <td>0.3691</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.3927</td>\n",
       "      <td>0.3308</td>\n",
       "      <td>0.1085</td>\n",
       "      <td>0.1139</td>\n",
       "      <td>0.3446</td>\n",
       "      <td>0.5441</td>\n",
       "      <td>0.6470</td>\n",
       "      <td>0.7276</td>\n",
       "      <td>0.7894</td>\n",
       "      <td>0.8264</td>\n",
       "      <td>0.8697</td>\n",
       "      <td>0.7836</td>\n",
       "      <td>0.7140</td>\n",
       "      <td>0.5698</td>\n",
       "      <td>0.2908</td>\n",
       "      <td>0.4636</td>\n",
       "      <td>0.6409</td>\n",
       "      <td>0.7405</td>\n",
       "      <td>0.8069</td>\n",
       "      <td>0.8420</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9536</td>\n",
       "      <td>0.6755</td>\n",
       "      <td>0.3905</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>0.3629</td>\n",
       "      <td>0.6356</td>\n",
       "      <td>0.8116</td>\n",
       "      <td>0.7664</td>\n",
       "      <td>0.5417</td>\n",
       "      <td>0.2614</td>\n",
       "      <td>0.1723</td>\n",
       "      <td>0.2814</td>\n",
       "      <td>0.2764</td>\n",
       "      <td>0.1985</td>\n",
       "      <td>0.1502</td>\n",
       "      <td>0.1219</td>\n",
       "      <td>0.0493</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.0446</td>\n",
       "      <td>0.0551</td>\n",
       "      <td>0.0597</td>\n",
       "      <td>0.1416</td>\n",
       "      <td>0.0956</td>\n",
       "      <td>0.0802</td>\n",
       "      <td>0.1618</td>\n",
       "      <td>0.2558</td>\n",
       "      <td>0.3078</td>\n",
       "      <td>0.3404</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.3951</td>\n",
       "      <td>0.3352</td>\n",
       "      <td>0.2252</td>\n",
       "      <td>0.2086</td>\n",
       "      <td>0.2248</td>\n",
       "      <td>0.3382</td>\n",
       "      <td>0.4578</td>\n",
       "      <td>0.6474</td>\n",
       "      <td>0.6708</td>\n",
       "      <td>0.7007</td>\n",
       "      <td>0.7619</td>\n",
       "      <td>0.7745</td>\n",
       "      <td>0.6767</td>\n",
       "      <td>0.7373</td>\n",
       "      <td>0.7834</td>\n",
       "      <td>0.9619</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8086</td>\n",
       "      <td>0.5558</td>\n",
       "      <td>0.5409</td>\n",
       "      <td>0.4988</td>\n",
       "      <td>0.3108</td>\n",
       "      <td>0.2897</td>\n",
       "      <td>0.2244</td>\n",
       "      <td>0.0960</td>\n",
       "      <td>0.2287</td>\n",
       "      <td>0.3228</td>\n",
       "      <td>0.3454</td>\n",
       "      <td>0.3882</td>\n",
       "      <td>0.3240</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>0.1173</td>\n",
       "      <td>0.0566</td>\n",
       "      <td>0.0766</td>\n",
       "      <td>0.0969</td>\n",
       "      <td>0.0588</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0641</td>\n",
       "      <td>0.1732</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.2559</td>\n",
       "      <td>0.2947</td>\n",
       "      <td>0.4110</td>\n",
       "      <td>0.4983</td>\n",
       "      <td>0.5920</td>\n",
       "      <td>0.5832</td>\n",
       "      <td>0.5419</td>\n",
       "      <td>0.5472</td>\n",
       "      <td>0.5314</td>\n",
       "      <td>0.4981</td>\n",
       "      <td>0.6985</td>\n",
       "      <td>0.8292</td>\n",
       "      <td>0.7839</td>\n",
       "      <td>0.8215</td>\n",
       "      <td>0.9363</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9224</td>\n",
       "      <td>0.7839</td>\n",
       "      <td>0.5470</td>\n",
       "      <td>0.4562</td>\n",
       "      <td>0.5922</td>\n",
       "      <td>0.5448</td>\n",
       "      <td>0.3971</td>\n",
       "      <td>0.0882</td>\n",
       "      <td>0.2385</td>\n",
       "      <td>0.2005</td>\n",
       "      <td>0.0587</td>\n",
       "      <td>0.2544</td>\n",
       "      <td>0.2009</td>\n",
       "      <td>0.0329</td>\n",
       "      <td>0.1547</td>\n",
       "      <td>0.1212</td>\n",
       "      <td>0.2446</td>\n",
       "      <td>0.3171</td>\n",
       "      <td>0.3195</td>\n",
       "      <td>0.3051</td>\n",
       "      <td>0.0836</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.1381</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>0.0516</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0278</td>\n",
       "      <td>0.0372</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "67   0.0368  0.0403  0.0317  0.0293  0.0820  0.1342  0.1161  0.0663  0.0155   \n",
       "14   0.0124  0.0433  0.0604  0.0449  0.0597  0.0355  0.0531  0.0343  0.1052   \n",
       "164  0.0163  0.0198  0.0202  0.0386  0.0752  0.1444  0.1487  0.1484  0.2442   \n",
       "179  0.0394  0.0420  0.0446  0.0551  0.0597  0.1416  0.0956  0.0802  0.1618   \n",
       "19   0.0126  0.0149  0.0641  0.1732  0.2565  0.2559  0.2947  0.4110  0.4983   \n",
       "\n",
       "         9       10      11      12      13      14      15      16      17  \\\n",
       "67   0.0506  0.0906  0.2545  0.1464  0.1272  0.1223  0.1669  0.1424  0.1285   \n",
       "14   0.2120  0.1640  0.1901  0.3026  0.2019  0.0592  0.2390  0.3657  0.3809   \n",
       "164  0.2822  0.3691  0.3750  0.3927  0.3308  0.1085  0.1139  0.3446  0.5441   \n",
       "179  0.2558  0.3078  0.3404  0.3400  0.3951  0.3352  0.2252  0.2086  0.2248   \n",
       "19   0.5920  0.5832  0.5419  0.5472  0.5314  0.4981  0.6985  0.8292  0.7839   \n",
       "\n",
       "         18      19      20      21      22      23      24      25      26  \\\n",
       "67   0.1857  0.1136  0.2069  0.0219  0.2400  0.2547  0.0240  0.1923  0.4753   \n",
       "14   0.5929  0.6299  0.5801  0.4574  0.4449  0.3691  0.6446  0.8940  0.8978   \n",
       "164  0.6470  0.7276  0.7894  0.8264  0.8697  0.7836  0.7140  0.5698  0.2908   \n",
       "179  0.3382  0.4578  0.6474  0.6708  0.7007  0.7619  0.7745  0.6767  0.7373   \n",
       "19   0.8215  0.9363  1.0000  0.9224  0.7839  0.5470  0.4562  0.5922  0.5448   \n",
       "\n",
       "         27      28      29      30      31      32      33      34      35  \\\n",
       "67   0.7003  0.6825  0.6443  0.7063  0.5373  0.6601  0.8708  0.9518  0.9605   \n",
       "14   0.4980  0.3333  0.2350  0.1553  0.3666  0.4340  0.3082  0.3024  0.4109   \n",
       "164  0.4636  0.6409  0.7405  0.8069  0.8420  1.0000  0.9536  0.6755  0.3905   \n",
       "179  0.7834  0.9619  1.0000  0.8086  0.5558  0.5409  0.4988  0.3108  0.2897   \n",
       "19   0.3971  0.0882  0.2385  0.2005  0.0587  0.2544  0.2009  0.0329  0.1547   \n",
       "\n",
       "         36      37      38      39      40      41      42      43      44  \\\n",
       "67   0.7712  0.6772  0.6431  0.6720  0.6035  0.5155  0.3802  0.2278  0.1522   \n",
       "14   0.5501  0.4129  0.5499  0.5018  0.3132  0.2802  0.2351  0.2298  0.1155   \n",
       "164  0.1249  0.3629  0.6356  0.8116  0.7664  0.5417  0.2614  0.1723  0.2814   \n",
       "179  0.2244  0.0960  0.2287  0.3228  0.3454  0.3882  0.3240  0.0926  0.1173   \n",
       "19   0.1212  0.2446  0.3171  0.3195  0.3051  0.0836  0.1266  0.1381  0.1136   \n",
       "\n",
       "         45      46      47      48      49      50      51      52      53  \\\n",
       "67   0.0801  0.0804  0.0752  0.0566  0.0175  0.0058  0.0091  0.0160  0.0160   \n",
       "14   0.0724  0.0621  0.0318  0.0450  0.0167  0.0078  0.0083  0.0057  0.0174   \n",
       "164  0.2764  0.1985  0.1502  0.1219  0.0493  0.0027  0.0077  0.0026  0.0031   \n",
       "179  0.0566  0.0766  0.0969  0.0588  0.0050  0.0118  0.0146  0.0040  0.0114   \n",
       "19   0.0516  0.0073  0.0278  0.0372  0.0121  0.0153  0.0092  0.0035  0.0098   \n",
       "\n",
       "         54      55      56      57      58      59  \n",
       "67   0.0081  0.0070  0.0135  0.0067  0.0078  0.0068  \n",
       "14   0.0188  0.0054  0.0114  0.0196  0.0147  0.0062  \n",
       "164  0.0083  0.0020  0.0084  0.0108  0.0083  0.0033  \n",
       "179  0.0032  0.0062  0.0101  0.0068  0.0053  0.0087  \n",
       "19   0.0121  0.0006  0.0181  0.0094  0.0116  0.0063  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Deep Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model without Dropout Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 2ms/step - loss: 0.6905 - accuracy: 0.5321\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6696 - accuracy: 0.6218\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6987\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6214 - accuracy: 0.7500\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5943 - accuracy: 0.7500\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.7885\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5360 - accuracy: 0.7628\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.8077\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.8205\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.8397\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8397\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8590\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3553 - accuracy: 0.8590\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8654\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8654\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8526\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2878 - accuracy: 0.9231\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2722 - accuracy: 0.9359\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2697 - accuracy: 0.9167\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2665 - accuracy: 0.9103\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2387 - accuracy: 0.9423\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2407 - accuracy: 0.9295\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2250 - accuracy: 0.9359\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2590 - accuracy: 0.9103\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2140 - accuracy: 0.9359\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2071 - accuracy: 0.9423\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2206 - accuracy: 0.9167\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2034 - accuracy: 0.9359\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.1931 - accuracy: 0.9423\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.1785 - accuracy: 0.9423\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.1863 - accuracy: 0.9551\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.1593 - accuracy: 0.9615\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.1491 - accuracy: 0.9615\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.1462 - accuracy: 0.9615\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.1431 - accuracy: 0.9744\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.1672 - accuracy: 0.9551\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.1676 - accuracy: 0.9295\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.1706 - accuracy: 0.9231\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.1206 - accuracy: 0.9744\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.1368 - accuracy: 0.9487\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.1108 - accuracy: 0.9744\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.1071 - accuracy: 0.9808\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.1016 - accuracy: 0.9808\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0881 - accuracy: 0.9872\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0804 - accuracy: 0.9808\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.1391 - accuracy: 0.9551\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.1235 - accuracy: 0.9423\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0898 - accuracy: 0.9808\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0796 - accuracy: 0.9808\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0693 - accuracy: 0.9872\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0751 - accuracy: 0.9808\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0828 - accuracy: 0.9744\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 0.9936\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0439 - accuracy: 0.9936\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0395 - accuracy: 0.9936\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0367 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0313 - accuracy: 0.9936\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0376 - accuracy: 0.9936\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0286 - accuracy: 0.9936\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0250 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0407 - accuracy: 0.9872\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9936\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0186 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0159 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0291 - accuracy: 0.9872\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0175 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18df1469450>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(60, input_dim=60, activation='relu'),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dense(15, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Accuracy >>> Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = model.predict(X_test).reshape(-1)\n",
    "#print(y_pred[:10])\n",
    "\n",
    "# round the values to nearest integer ie 0 or 1\n",
    "#y_pred = np.round(y_pred)\n",
    "#print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import confusion_matrix , classification_report\n",
    "\n",
    "#print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with Dropout Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 3ms/step - loss: 0.6970 - accuracy: 0.4936\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7079 - accuracy: 0.5449\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7024 - accuracy: 0.4551\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6986 - accuracy: 0.5064\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6921 - accuracy: 0.5192\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6865 - accuracy: 0.5321\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6958 - accuracy: 0.5064\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6793 - accuracy: 0.5962\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6823 - accuracy: 0.5513\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6875 - accuracy: 0.5705\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6795 - accuracy: 0.5769\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6625 - accuracy: 0.5833\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6781 - accuracy: 0.5769\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6682 - accuracy: 0.5833\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6679 - accuracy: 0.5641\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6497 - accuracy: 0.6218\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6365 - accuracy: 0.6667\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6571 - accuracy: 0.5897\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6549 - accuracy: 0.6154\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6251 - accuracy: 0.6474\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6488 - accuracy: 0.5962\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6324 - accuracy: 0.6538\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6821 - accuracy: 0.5705\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6504 - accuracy: 0.5897\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6363 - accuracy: 0.6474\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6204 - accuracy: 0.6667\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6046 - accuracy: 0.7244\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5998 - accuracy: 0.6923\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5852 - accuracy: 0.7051\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5719 - accuracy: 0.7179\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6190 - accuracy: 0.7179\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5860 - accuracy: 0.7308\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5488 - accuracy: 0.7628\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5629 - accuracy: 0.7436\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6030 - accuracy: 0.7179\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5348 - accuracy: 0.7436\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5172 - accuracy: 0.7949\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5143 - accuracy: 0.7692\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.7436\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5346 - accuracy: 0.7372\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4840 - accuracy: 0.7821\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.8077\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.7949\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4875 - accuracy: 0.7885\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.8333\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4534 - accuracy: 0.8141\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4851 - accuracy: 0.7821\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.4897 - accuracy: 0.8205\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.8013\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4165 - accuracy: 0.8654\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.8013\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5251 - accuracy: 0.7436\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.8141\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7885\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.8077\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4138 - accuracy: 0.8462\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.8526\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3953 - accuracy: 0.8526\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7949\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3823 - accuracy: 0.8590\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8013\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3931 - accuracy: 0.8205\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4020 - accuracy: 0.8205\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.8269\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4102 - accuracy: 0.8397\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3865 - accuracy: 0.8333\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3464 - accuracy: 0.8654\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3385 - accuracy: 0.8526\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3459 - accuracy: 0.8526\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3403 - accuracy: 0.8590\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3645 - accuracy: 0.8590\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3426 - accuracy: 0.8397\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2909 - accuracy: 0.8910\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8269\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3658 - accuracy: 0.8718\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3587 - accuracy: 0.8590\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3736 - accuracy: 0.8590\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3279 - accuracy: 0.9103\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3155 - accuracy: 0.8910\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2973 - accuracy: 0.9103\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3620 - accuracy: 0.8526\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3377 - accuracy: 0.8910\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3181 - accuracy: 0.8846\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3482 - accuracy: 0.8397\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2883 - accuracy: 0.8718\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2955 - accuracy: 0.9167\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2809 - accuracy: 0.9167\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2806 - accuracy: 0.9231\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2522 - accuracy: 0.9295\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2985 - accuracy: 0.8718\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3211 - accuracy: 0.9295\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3212 - accuracy: 0.8910\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2553 - accuracy: 0.8974\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2952 - accuracy: 0.8846\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2551 - accuracy: 0.9167\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3058 - accuracy: 0.8910\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2979 - accuracy: 0.8846\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2912 - accuracy: 0.8590\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2236 - accuracy: 0.9231\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2572 - accuracy: 0.8910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18df1441d50>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeld = keras.Sequential([\n",
    "    keras.layers.Dense(60, input_dim=60, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(15, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "modeld.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "modeld.fit(X_train, y_train, epochs=100, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x0000018DF250D990> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.43553924560546875, 0.7692307829856873]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeld.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Accuracy is still good but Test Accuracy Improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n",
      "[0.0024609  0.7915153  0.9144191  0.05611353 0.9996545  0.95766705\n",
      " 0.3951249  0.9995616  0.05497704 0.99995416]\n",
      "[0. 1. 1. 0. 1. 1. 0. 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "y_pred = modeld.predict(X_test).reshape(-1)\n",
    "print(y_pred[:10])\n",
    "\n",
    "# round the values to nearest integer ie 0 or 1\n",
    "y_pred = np.round(y_pred)\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.89      0.80        27\n",
      "           1       0.84      0.64      0.73        25\n",
      "\n",
      "    accuracy                           0.77        52\n",
      "   macro avg       0.78      0.76      0.76        52\n",
      "weighted avg       0.78      0.77      0.77        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can see that by using dropout layer test accuracy increased from 0.77 to 0.81**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('models_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aa4c39f05347c183750aec384d7fec9b2b00b3dba304e15bc52203706b206acd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
